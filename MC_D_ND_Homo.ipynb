{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3bWtY-YEysIh"
      },
      "source": [
        "# MC Simulations with both DC and NDC in a homogeneous group\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B7a22i7HnSYl",
        "outputId": "025b2e43-43d9-4da6-98bd-10fbdbda1a9b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting fast-pagerank\n",
            "  Downloading fast_pagerank-0.0.4-py3-none-any.whl (5.2 kB)\n",
            "Installing collected packages: fast-pagerank\n",
            "Successfully installed fast-pagerank-0.0.4\n",
            "Collecting faiss-gpu\n",
            "  Downloading faiss_gpu-1.7.2-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (85.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 85.5 MB 108 kB/s \n",
            "\u001b[?25hInstalling collected packages: faiss-gpu\n",
            "Successfully installed faiss-gpu-1.7.2\n",
            "Total Time 79258.09906816483\n"
          ]
        }
      ],
      "source": [
        "# Libraries\n",
        "\n",
        "!pip install fast-pagerank\n",
        "\n",
        "from IPython import get_ipython\n",
        "get_ipython().magic('reset -sf')\n",
        "!pip install faiss-gpu\n",
        "import faiss\n",
        "import numpy as np\n",
        "import torch\n",
        "import random\n",
        "import networkx as nx\n",
        "import time\n",
        "from scipy import sparse\n",
        "from fast_pagerank import pagerank\n",
        "from fast_pagerank import pagerank_power\n",
        "device='cuda'\n",
        "res = faiss.StandardGpuResources()\n",
        "\n",
        "# Total number of agents\n",
        "N = np.arange(200,1200,step=200)\n",
        "op_tol = np.array([5,10,15,20,25,30])*np.pi/180\n",
        "# Mean opinion value of the initial distribution\n",
        "mu = 90*np.pi/180\n",
        "# Variance of the initial opinion distribution\n",
        "var = np.array([10,20])*np.pi/180\n",
        "# Maximum in-degree of agents\n",
        "max_degree = np.arange(0.25,1.25,step=0.25)\n",
        "# Minimum in-degree of agents\n",
        "min_degree = 0.05\n",
        "# Total simulation time\n",
        "Final_Time = 1000\n",
        "# Monte Carlo Runs\n",
        "Monte_Carlo = 100\n",
        "Total_Size = len(N)*len(var)*len(max_degree)*len(op_tol)\n",
        "\n",
        "start=time.time()\n",
        "def generate_random_graph(c_t,min_d,max_d,Total_Agents, Mean, Variance,Identity_Matrix):\n",
        "  ''' \n",
        "  \n",
        "  Generate a connected network based on opinion similarity with no opinion leaders\n",
        "  \n",
        "  '''\n",
        "  not_connected = True \n",
        "  leaders = True\n",
        "  Separation = torch.zeros((Total_Agents,Total_Agents),dtype=torch.double,device='cuda')\n",
        "  Neighbors = torch.zeros((Total_Agents,Total_Agents),device='cuda')\n",
        "\n",
        "  Adjacency_Matrix = torch.zeros((Total_Agents,Total_Agents),dtype=torch.double,device='cuda')\n",
        "  # Indices Padding\n",
        "  Padding = torch.arange(0,Total_Agents,step=1,device='cuda')[:,None]*torch.ones((Total_Agents,max_d),\n",
        "            dtype=torch.long,device='cuda')\n",
        "  In_degree = torch.zeros((Total_Agents,),dtype=torch.long,device='cuda')\n",
        "  while not_connected:\n",
        "    leaders = True\n",
        "    while leaders:\n",
        "      Opinions = torch.normal(Mean,Variance,(Total_Agents,),device='cuda')\n",
        "      Max_Degree = torch.randint(min_d,max_d,(Total_Agents,)).cuda()\n",
        "      # Find neighbors upto max_degree\n",
        "      # Pytorch to numpy\n",
        "      Current = np.float32(Opinions.cpu().detach().numpy())\n",
        "      index_flat = faiss.IndexFlatL2(Current[:,None].shape[1])\n",
        "      gpu_index_flat = faiss.index_cpu_to_gpu(res, 0, index_flat)\n",
        "      gpu_index_flat.add(Current[:,None])\n",
        "      m, n = gpu_index_flat.search(Current[:,None], max_d)\n",
        "      tensor_n = torch.from_numpy(n).long()\n",
        "      # Indices of possible neighbors\n",
        "      Neighbors[Padding, tensor_n] = 1\n",
        "      # Value Separation \n",
        "      Separation[Padding, tensor_n] = torch.squeeze(torch.cdist(Opinions[:,None][:,None],Opinions[:,None][tensor_n],p=2)).double()\n",
        "      Separation[Neighbors==0] = Total_Agents           \n",
        "      Adjacency_Matrix[torch.logical_and(Separation<=c_t[:,None],Neighbors==1)] = 1\n",
        "      Adjacency_Matrix -= Identity_Matrix\n",
        "      Adjacency_Matrix[torch.where(torch.cumsum(Adjacency_Matrix,axis=1)>Max_Degree[:,None])]=0\n",
        "      # Check for leaders\n",
        "      In_Degree = torch.sum(Adjacency_Matrix,1)\n",
        "      if torch.where(In_Degree==0)[0].size(0)==0:\n",
        "        leaders = False\n",
        "    # Check for connectedness\n",
        "    G = nx.from_numpy_matrix(Adjacency_Matrix.cpu().detach().numpy(),create_using=nx.DiGraph)\n",
        "    if nx.is_weakly_connected(G)==True:\n",
        "      not_connected = False\n",
        "  return Adjacency_Matrix+Identity_Matrix,In_Degree,Neighbors,Separation,Opinions, Max_Degree\n",
        "\n",
        "def neighbors_and_weights(Total_Agents,Node_Weights,Adjacency_Matrix,Identity_Matrix,Separation,Tol):\n",
        "  '''\n",
        "  (a) Assign weights to the direct ties\n",
        "  (b) Find 2/3 hop neighbors and weights\n",
        "  (c) Comment 2/3-hop portions when not considered in simulations\n",
        "  '''\n",
        "  \n",
        "  # Direct Ties: 1-Hop\n",
        "  adj_matrix = Adjacency_Matrix-Identity_Matrix\n",
        "  # 2-Hop\n",
        "  two_hop_matrix = torch.zeros((Total_Agents,Total_Agents),device='cuda',dtype=torch.double)\n",
        "  two_hop_matrix = adj_matrix*adj_matrix\n",
        "  # 3-Hop\n",
        "  three_hop_matrix = torch.zeros((Total_Agents,Total_Agents),device='cuda',dtype=torch.double)\n",
        "  three_hop_matrix = adj_matrix*adj_matrix*adj_matrix\n",
        "\n",
        "  # Weights of Direct Ties\n",
        "  w_matrix = torch.rand(Total_Agents,Total_Agents,device='cuda',dtype=torch.double)\n",
        "  # Self-weights and non-direct ties are 0s\n",
        "  w_matrix[adj_matrix==0] = 0\n",
        "\n",
        "  # Weights of 2-Hop Ties\n",
        "  two_hop_w_matrix = w_matrix*w_matrix\n",
        "\n",
        "  # Weights of 3-Hop Ties\n",
        "  three_hop_w_matrix = w_matrix*w_matrix*w_matrix\n",
        "\n",
        "  # Both 2-hop and 3-hop tie\n",
        "  condition = torch.logical_and(torch.logical_and(two_hop_matrix!=0,three_hop_matrix!=0),adj_matrix==0)\n",
        "  w_matrix[condition] = (two_hop_w_matrix[condition]+three_hop_w_matrix[condition])/(two_hop_matrix[condition]+three_hop_matrix[condition])\n",
        "\n",
        "  # Only 2-hop tie\n",
        "  condition = torch.logical_and(torch.logical_and(two_hop_matrix!=0,three_hop_matrix==0),adj_matrix==0)\n",
        "  w_matrix[condition] = two_hop_w_matrix[condition]/two_hop_matrix[condition]\n",
        "\n",
        "  # Only 3-hop tie\n",
        "  condition = torch.logical_and(torch.logical_and(two_hop_matrix==0,three_hop_matrix!=0),adj_matrix==0)\n",
        "  w_matrix[condition] = three_hop_w_matrix[condition]/three_hop_matrix[condition]\n",
        "\n",
        "  # Chosen Neighbors\n",
        "  final_matrix = two_hop_matrix + three_hop_matrix\n",
        "  # Choose Congenial Neighbors Uniformly at Random\n",
        "  final_matrix[torch.logical_and(torch.logical_and(torch.rand((Total_Agents,Total_Agents),device='cuda')<0.5,final_matrix!=0),Separation<=Tol)] = 1\n",
        "  \n",
        "  # Reset Weights of Non-chosen 2/3 Hop Ties\n",
        "  w_matrix[final_matrix==0] = 0\n",
        "  # To ensure that the row sum is equal to (1-Node_Weight)\n",
        "  scale = (1-Node_Weights)/torch.sum(w_matrix,1)\n",
        "  condition = torch.isinf(scale)\n",
        "  w_matrix[condition==False] = w_matrix[condition==False]*scale[condition==False,None]\n",
        "  # Self-weights\n",
        "  w_matrix+=(Node_Weights*Identity_Matrix)\n",
        "  \n",
        "  return final_matrix!=0, w_matrix   \n",
        "\n",
        "Mean_Values = torch.zeros((10,Total_Size),dtype=torch.double,device='cuda')\n",
        "Std_Values = torch.zeros((10,Total_Size),dtype=torch.double,device='cuda')\n",
        "outer_count = 0\n",
        "\n",
        "for g_var in range(len(var)): # Different group variance\n",
        "  for g_size in range(len(N)): # Different Group Sizes\n",
        "    for ind_tol in range(len(op_tol)): # Different stubborn population\n",
        "      for max_deg in range(len(max_degree)): # Different in-degree\n",
        "        # MonteCarlo Values: 0: Initial Opinions, 1: Final Opinions, 2: Updates, 3: Initial In-degree\n",
        "        # 4: Final In-degree, 5: Initial Out-degree, 6: Final Out-degree, 7: Node-Weights\n",
        "        Final_Values = torch.zeros((10,Monte_Carlo,N[len(N)-1]),dtype=torch.double,device='cuda')\n",
        "        Groups = torch.zeros((2,Monte_Carlo),dtype=torch.long,device='cuda')\n",
        "        for mc in range(Monte_Carlo): # Monte Carlo Simulations for each variable configuration\n",
        "    \n",
        "          # Vectors carrying agent attributes\n",
        "          # 0: Opinion, 1: Weights, 2: In-degree, 3: Out-degree, 4: Opinion tolerance,\n",
        "          # 5: Individual Maximum In-Degree, 6: Opinion Update, 7: Sociability Threshold\n",
        "          Agents = torch.zeros((N[g_size],8),dtype=torch.double,device='cuda')\n",
        "          Agents[:,4] = op_tol[ind_tol]\n",
        "          #Agents[torch.randperm(N[g_size])[:int(s_pop[pop]*N[g_size])],4] = s_tol\n",
        "          # Matrices with values\n",
        "          # 0: Adjacency Matrix, 1: Opinion Difference, 2: Neighbors, \n",
        "          # 3: Identity Matrix, 4: Tie Weights, 5: Two-hop, 6: Three-hop\n",
        "          Square_Matrixs = torch.zeros((7,N[g_size],N[g_size]),dtype=torch.double,device='cuda')\n",
        "          Square_Matrixs[3] = torch.eye(N[g_size],dtype=torch.double,device='cuda')\n",
        "          \n",
        "          # Time Series: 0: Opinions, 1: Updating Agents, 2: In-degree, 3: Out-degree\n",
        "          TimeSeries_Values = torch.zeros((5,N[g_size],Final_Time),dtype=torch.double,device='cuda')\n",
        "\n",
        "          # Generate an initially connected network with no leaders\n",
        "          Square_Matrixs[0], Agents[:,2], Square_Matrixs[2], Square_Matrixs[1], Agents[:,0], Agents[:,5] = generate_random_graph(Agents[:,4],int(N[g_size]*min_degree),int(N[g_size]*max_degree[max_deg]),N[g_size],mu,var[g_var],Square_Matrixs[3])\n",
        "          \n",
        "          # Assign Popularity \n",
        "          Agents[:,7] = torch.from_numpy(pagerank(sparse.csr_matrix((Square_Matrixs[0]-Square_Matrixs[3]).cpu().detach().numpy()),p=0.9))\n",
        "          # Sociability threshold\n",
        "          Social_Thresh = int((1/torch.mean(Agents[:,7])).item())*10\n",
        "          Agents[:,7] *= Social_Thresh\n",
        "\n",
        "          # Assign Node weights \n",
        "          Agents[:,1] = torch.rand((N[g_size],))\n",
        "\n",
        "          # Main time-series simulation\n",
        "          for t in range(Final_Time):\n",
        "\n",
        "            # Opinions\n",
        "            TimeSeries_Values[0][:,t] = Agents[:,0]\n",
        "            # In-degree\n",
        "            TimeSeries_Values[2][:,t] = torch.sum(Square_Matrixs[0]-Square_Matrixs[3],1)\n",
        "            # Out-degree\n",
        "            TimeSeries_Values[3][:,t] = torch.sum(Square_Matrixs[0]-Square_Matrixs[3],0)\n",
        "            # Number of Agents Updating in the Current Iteration and not leaders\n",
        "            Agents[torch.logical_and(torch.rand((N[g_size],),device='cuda')<=0.5,TimeSeries_Values[2][:,t]!=0),6] = 1\n",
        "            # Agents Updating their Opinion in the Current Iteration\n",
        "            TimeSeries_Values[1][:,t] = Agents[:,6]\n",
        "            # Sociability\n",
        "            TimeSeries_Values[4][:,t] = Agents[:,7]\n",
        "            # 2-hop/3-hop chosen neighbors, Tie Weights (Direct + Chosen 2/3 Hops)\n",
        "            Square_Matrixs[5], Square_Matrixs[4] = neighbors_and_weights(N[g_size],Agents[:,1],Square_Matrixs[0],Square_Matrixs[3],Square_Matrixs[1],Agents[:,4][:,None])\n",
        "            # Verification ( Negative or undefined weights)\n",
        "            # Opinion update\n",
        "            Agents[Agents[:,6]==1,0] = torch.atan2(torch.sum((Square_Matrixs[4]*torch.sin(Agents[:,0]*torch.ones((N[g_size],N[g_size]),device='cuda'))),1),torch.sum((Square_Matrixs[4]*torch.cos(Agents[:,0]*torch.ones((N[g_size],N[g_size]),device='cuda'))),1))[Agents[:,6]==1]\n",
        "            # Opinion separation\n",
        "            Square_Matrixs[1] = torch.cdist(Agents[:,0][:,None],Agents[:,0][:,None],p=2) \n",
        "            # Update neighborhood: \n",
        "            # 2/3-Hop neighbors with Opinions within confidence threshold\n",
        "            Square_Matrixs[6][torch.logical_and(Square_Matrixs[1]<=Agents[:,4][:,None],Square_Matrixs[5]==1)]+=1\n",
        "            Square_Matrixs[6][Square_Matrixs[0]==1] = 0\n",
        "            # New direct ties\n",
        "            Square_Matrixs[0][Square_Matrixs[6]>=torch.round(Agents[:,7][:,None]*torch.ones((N[g_size],N[g_size]),device='cuda'))] = 1\n",
        "            # Delete old ties\n",
        "            Square_Matrixs[0][torch.logical_and(Square_Matrixs[1]>Agents[:,4][:,None],Square_Matrixs[0]==1)] = 0\n",
        "            # Reset updating agents\n",
        "            Agents[:,6] = 0\n",
        "          # Initial Opinion Distribution    \n",
        "          Final_Values[0][mc][:N[g_size]] = TimeSeries_Values[0][:,0]\n",
        "          # Final Opinion Distribution\n",
        "          Final_Values[1][mc][:N[g_size]] = TimeSeries_Values[0][:,t]\n",
        "          # Total Updates\n",
        "          Final_Values[2][mc][:N[g_size]] = torch.mean(TimeSeries_Values[1],1)\n",
        "          # Initial In_degree\n",
        "          Final_Values[3][mc][:N[g_size]] = TimeSeries_Values[2][:,0]\n",
        "          # Final In_degree\n",
        "          Final_Values[4][mc][:N[g_size]] = TimeSeries_Values[2][:,t]\n",
        "          # Initial Out_degree\n",
        "          Final_Values[5][mc][:N[g_size]] = TimeSeries_Values[3][:,0]\n",
        "          # Final Out_degree\n",
        "          Final_Values[6][mc][:N[g_size]] = TimeSeries_Values[3][:,t]\n",
        "          # Node weights\n",
        "          Final_Values[7][mc][:N[g_size]] = Agents[:,1]\n",
        "          # Sociability (Initial)\n",
        "          Final_Values[8][mc][:N[g_size]] = TimeSeries_Values[4][:,0]\n",
        "          # Number of groups\n",
        "          G = nx.from_numpy_matrix(Square_Matrixs[0].cpu().detach().numpy(),create_using=nx.DiGraph)\n",
        "          Groups[0][mc] = max(len([len(c) for c in sorted(nx.weakly_connected_components(G),key=len, reverse=True)]),torch.unique(torch.round((Agents[:,0]*180/np.pi))).size(0))\n",
        "          #len([len(c) for c in sorted(nx.weakly_connected_components(G),key=len, reverse=True)])\n",
        "          Groups[1][mc] = len(max(list(nx.weakly_connected_components(G))))\n",
        "        # Average groups\n",
        "        Mean_Values[0][outer_count] = torch.mean(Groups[0].double())\n",
        "        Std_Values[0][outer_count] = torch.std(Groups[0].double())\n",
        "        # Average Consensus Rate\n",
        "        Mean_Values[1][outer_count] = torch.where(Groups[0]==1)[0].size(0)/Monte_Carlo\n",
        "        # Average Group Size\n",
        "        Mean_Values[2][outer_count] = torch.mean(Groups[1].double())\n",
        "        Std_Values[2][outer_count] = torch.std(Groups[1].double())\n",
        "        # In-degree\n",
        "        # Initial\n",
        "        Mean_Values[3][outer_count] = torch.mean(Final_Values[3])\n",
        "        Std_Values[3][outer_count] = torch.std(Final_Values[3])\n",
        "        # Final\n",
        "        Mean_Values[4][outer_count] = torch.mean(Final_Values[4])\n",
        "        Std_Values[4][outer_count] = torch.std(Final_Values[4])      \n",
        "        # Out-degree\n",
        "        # Initial\n",
        "        Mean_Values[5][outer_count] = torch.mean(Final_Values[5])\n",
        "        Std_Values[5][outer_count] = torch.std(Final_Values[5])\n",
        "        # Final\n",
        "        Mean_Values[6][outer_count] = torch.mean(Final_Values[6])\n",
        "        Std_Values[6][outer_count] = torch.std(Final_Values[6])     \n",
        "        # Node weights\n",
        "        Mean_Values[7][outer_count] = torch.mean(Final_Values[7])\n",
        "        Std_Values[7][outer_count] = torch.std(Final_Values[7])    \n",
        "        # Sociability\n",
        "        Mean_Values[8][outer_count] = torch.mean(Final_Values[8])\n",
        "        Std_Values[8][outer_count] = torch.std(Final_Values[8])            \n",
        "        # Updates\n",
        "        Mean_Values[9][outer_count] = torch.mean(Final_Values[2])\n",
        "        Std_Values[9][outer_count] = torch.std(Final_Values[2])  \n",
        "        outer_count+=1         \n",
        "end=time.time()\n",
        "print('Total Time',end-start)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qtd6nA6ktQ4T"
      },
      "outputs": [],
      "source": [
        "!pip install hickle\n",
        "import hickle as hk\n",
        "from google.colab import files\n",
        "name = \"DNDHomogeneous_Mean\"\n",
        "hk.dump(Mean_Values.cpu().detach().numpy(),'{0}.hkl'.format(name), mode='w')\n",
        "files.download('{0}.hkl'.format(name))\n",
        "name = \"DNDHomogeneous_Std\"\n",
        "hk.dump(Std_Values.cpu().detach().numpy(),'{0}.hkl'.format(name), mode='w')\n",
        "files.download('{0}.hkl'.format(name))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hueHN8vld_0b"
      },
      "source": [
        "## Load Files"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Jj1L5JDUucZz"
      },
      "outputs": [],
      "source": [
        "%reset -f\n",
        "from matplotlib import pyplot as plt\n",
        "from IPython.display import HTML\n",
        "import seaborn as sns\n",
        "from matplotlib.ticker import AutoMinorLocator, MultipleLocator\n",
        "from matplotlib.colors import ListedColormap, LinearSegmentedColormap\n",
        "from matplotlib import collections as matcoll\n",
        "from matplotlib import cm\n",
        "import numpy as np\n",
        "from google.colab import files\n",
        "from scipy.stats import norm\n",
        "!pip install hickle\n",
        "import hickle as hkl\n",
        "from google.colab import files\n",
        "import torch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XxOyR4BQu6-v"
      },
      "outputs": [],
      "source": [
        "mean = hkl.load('DirectOnlyHomogeneous_Mean.hkl')\n",
        "max_degree = np.arange(0.25,1.25,step=0.25)\n",
        "# Minimum in-degree of agents\n",
        "min_degree = 0.05\n",
        "# Confidence threshold\n",
        "s_pop = np.arange(0,1.1,step=0.1)\n",
        "N = np.arange(200,1200,step=200)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lS-dH82lv1nl"
      },
      "source": [
        "## Consensus Rate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XsYZr1yGvQ_8"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "index = 0 # vary from 0 to 4\n",
        "group = 0 # vary from 0 to 1\n",
        "start_c = np.array([0,44,88,132,176])\n",
        "start_l = np.array([220,264,308,352,396])\n",
        "lables = np.array([\"5\",\"10\",\"15\",\"20\",\"25\",\"30\"])\n",
        "groups = np.array([\"Conservative\",\"Liberal\"])\n",
        "clrs = ['b','g','r','c','m','y','k','lawngreen','darkorange','dodgerblue','lightsteelblue']\n",
        "\n",
        "start=start_c\n",
        "\n",
        "start=start_c\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(8, 8))\n",
        "plt.plot(np.arange(0,4,step=1),mean[1][start[index]:start[index]+4],'s-',linewidth=3,linestyle='-',color=clrs[0],label=\"$\\\\theta_{T_{i}}=%s^{\\\\circ}$\"%(lables[0],))\n",
        "plt.plot(np.arange(0,4,step=1),mean[1][start[index]+4:start[index]+8],'s-',linewidth=3,linestyle='-',color=clrs[1],label=\"$\\\\theta_{T_{i}}=%s^{\\\\circ}$\"%(lables[1],))\n",
        "plt.plot(np.arange(0,4,step=1),mean[1][start[index]+8:start[index]+12],'s-',linewidth=3,linestyle='-',color=clrs[2],label=\"$\\\\theta_{T_{i}}=%s^{\\\\circ}$\"%(lables[2],))\n",
        "plt.plot(np.arange(0,4,step=1),mean[1][start[index]+12:start[index]+16],'s-',linewidth=3,linestyle='-',color=clrs[3],label=\"$\\\\theta_{T_{i}}=%s^{\\\\circ}$\"%(lables[3],))\n",
        "plt.plot(np.arange(0,4,step=1),mean[1][start[index]+16:start[index]+20],'s-',linewidth=3,linestyle='-',color=clrs[4],label=\"$\\\\theta_{T_{i}}=%s^{\\\\circ}$\"%(lables[4],))\n",
        "plt.plot(np.arange(0,4,step=1),mean[1][start[index]+20:start[index]+24],'s-',linewidth=3,linestyle='-',color=clrs[5],label=\"$\\\\theta_{T_{i}}=%s^{\\\\circ}$\"%(lables[5],))\n",
        "plt.rcParams['figure.facecolor'] = 'ivory'\n",
        "plt.rcParams[\"font.weight\"] = \"bold\"\n",
        "plt.rcParams[\"axes.labelweight\"] = \"bold\"\n",
        "ax.set_xticks(np.arange(0,4,step=1))\n",
        "ax.set_xticklabels([\"$0.25N$\",\"$0.5N$\",\"$0.75N$\",\"$1.0N$\"])\n",
        "plt.xticks(fontsize=18,fontweight='bold')\n",
        "plt.yticks(np.arange(0,1.2,step=0.1),fontsize=18,fontweight='bold')\n",
        "plt.xlabel('Maximum Out-degree ($D_{out_{max}}$)',fontsize=18,fontweight='bold')\n",
        "plt.ylabel('Consensus rate',fontsize=18,fontweight='bold')\n",
        "plt.title(\"{0} group of size, $N=%d$\".format(groups[group])%(N[index],),fontsize=18,fontweight='bold')\n",
        "leg = plt.legend(fontsize=18,loc=\"upper center\",fancybox=True,  bbox_to_anchor=(0.5, 1.3), ncol=3,\n",
        "           framealpha=1.0, shadow=False, borderpad=1)\n",
        "ax.grid(b=True, which='major', color='silver', linestyle='-')\n",
        "\n",
        "plt.savefig('DNDH{0}_Consensus_{1}.pdf'.format(groups[group],N[index]),format='pdf', bbox_inches='tight',Transparent=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lfosTA39iQh3"
      },
      "source": [
        "## Initial Out-degree"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ltb9g89TeSzK"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "index = 0 # vary from 0 to 4\n",
        "group = 0 # vary from 0 to 1\n",
        "start_c = np.array([0,44,88,132,176])\n",
        "start_l = np.array([220,264,308,352,396])\n",
        "lables = np.array([\"5\",\"10\",\"15\",\"20\",\"25\",\"30\"])\n",
        "groups = np.array([\"Conservative\",\"Liberal\"])\n",
        "clrs = ['b','g','r','c','m','y','k','lawngreen','darkorange','dodgerblue','lightsteelblue']\n",
        "\n",
        "start=start_c\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(8, 8))\n",
        "plt.plot(np.arange(0,4,step=1),mean[3][start[index]:start[index]+4],'s-',linewidth=3,linestyle='-',color=clrs[0],label=\"$\\\\theta_{T_{i}}=%s^{\\\\circ}$\"%(lables[0],))\n",
        "plt.plot(np.arange(0,4,step=1),mean[3][start[index]+4:start[index]+8],'s-',linewidth=3,linestyle='-',color=clrs[1],label=\"$\\\\theta_{T_{i}}=%s^{\\\\circ}$\"%(lables[1],))\n",
        "plt.plot(np.arange(0,4,step=1),mean[3][start[index]+8:start[index]+12],'s-',linewidth=3,linestyle='-',color=clrs[2],label=\"$\\\\theta_{T_{i}}=%s^{\\\\circ}$\"%(lables[2],))\n",
        "plt.plot(np.arange(0,4,step=1),mean[3][start[index]+12:start[index]+16],'s-',linewidth=3,linestyle='-',color=clrs[3],label=\"$\\\\theta_{T_{i}}=%s^{\\\\circ}$\"%(lables[3],))\n",
        "plt.plot(np.arange(0,4,step=1),mean[3][start[index]+16:start[index]+20],'s-',linewidth=3,linestyle='-',color=clrs[4],label=\"$\\\\theta_{T_{i}}=%s^{\\\\circ}$\"%(lables[4],))\n",
        "plt.plot(np.arange(0,4,step=1),mean[3][start[index]+20:start[index]+24],'s-',linewidth=3,linestyle='-',color=clrs[5],label=\"$\\\\theta_{T_{i}}=%s^{\\\\circ}$\"%(lables[5],))\n",
        "plt.rcParams['figure.facecolor'] = 'ivory'\n",
        "plt.rcParams[\"font.weight\"] = \"bold\"\n",
        "plt.rcParams[\"axes.labelweight\"] = \"bold\"\n",
        "ax.set_xticks(np.arange(0,4,step=1))\n",
        "ax.set_xticklabels([\"$0.25N$\",\"$0.5N$\",\"$0.75N$\",\"$1.0N$\"])\n",
        "plt.xticks(fontsize=18,fontweight='bold')\n",
        "plt.yticks(np.arange(0,55,step=5),fontsize=18,fontweight='bold')\n",
        "plt.xlabel('Maximum in-degree ($D_{out_{max}}$)',fontsize=18,fontweight='bold')\n",
        "plt.ylabel('Initial in-degree (mean %)',fontsize=18,fontweight='bold')\n",
        "plt.title(\"{0} group of size, $N=%d$\".format(groups[group])%(N[index],),fontsize=18,fontweight='bold')\n",
        "leg = plt.legend(fontsize=18,loc=\"upper center\",fancybox=True,  bbox_to_anchor=(0.5, 1.3), ncol=3,\n",
        "           framealpha=1.0, shadow=False, borderpad=1)\n",
        "ax.grid(b=True, which='major', color='silver', linestyle='-')\n",
        "\n",
        "plt.savefig('{0}_IOD_{1}.pdf'.format(groups[group],N[index]),format='pdf', bbox_inches='tight',Transparent=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I-h4IjqVvTlx"
      },
      "source": [
        "## Final Out-degree"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4Lxz17jxvV3K"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "index = 0 # vary from 0 to 4\n",
        "group = 0 # vary from 0 to 1\n",
        "start_c = np.array([0,44,88,132,176])\n",
        "start_l = np.array([220,264,308,352,396])\n",
        "lables = np.array([\"0\",\"10\",\"20\",\"30\",\"40\",\"50\",\"60\",\"70\",\"80\",\"90\",\"100\"])\n",
        "groups = np.array([\"Conservative\",\"Liberal\"])\n",
        "\n",
        "start=start_c\n",
        "\n",
        "factor = N[index]/100\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(8, 8))\n",
        "plt.plot(np.arange(0,4,step=1),mean[6][start[index]:start[index]+4]/factor,'s-',linewidth=3,linestyle='-',label=\"$\\\\theta_{T_{i}}=%s\\%%$\"%(lables[0],))\n",
        "plt.plot(np.arange(0,4,step=1),mean[6][start[index]+4:start[index]+8]/factor,'s-',linewidth=3,linestyle='-',label=\"$\\\\theta_{T_{i}}=%s\\%%$\"%(lables[1],))\n",
        "plt.plot(np.arange(0,4,step=1),mean[6][start[index]+8:start[index]+12]/factor,'s-',linewidth=3,linestyle='-',label=\"$\\\\theta_{T_{i}}=%s\\%%$\"%(lables[2],))\n",
        "plt.plot(np.arange(0,4,step=1),mean[6][start[index]+12:start[index]+16]/factor,'s-',linewidth=3,linestyle='-',label=\"$\\\\theta_{T_{i}}=%s\\%%$\"%(lables[3],))\n",
        "plt.plot(np.arange(0,4,step=1),mean[6][start[index]+16:start[index]+20]/factor,'s-',linewidth=3,linestyle='-',label=\"$\\\\theta_{T_{i}}=%s\\%%$\"%(lables[4],))\n",
        "plt.plot(np.arange(0,4,step=1),mean[6][start[index]+20:start[index]+24]/factor,'s-',linewidth=3,linestyle='-',label=\"$\\\\theta_{T_{i}}=%s\\%%$\"%(lables[5],))\n",
        "plt.plot(np.arange(0,4,step=1),mean[6][start[index]+24:start[index]+28]/factor,'s-',linewidth=3,linestyle='-',label=\"$\\\\theta_{T_{i}}=%s\\%%$\"%(lables[6],))\n",
        "plt.plot(np.arange(0,4,step=1),mean[6][start[index]+28:start[index]+32]/factor,'s-',linewidth=3,linestyle='-',label=\"$\\\\theta_{T_{i}}=%s\\%%$\"%(lables[7],))\n",
        "plt.plot(np.arange(0,4,step=1),mean[6][start[index]+32:start[index]+36]/factor,'s-',linewidth=3,linestyle='-',label=\"$\\\\theta_{T_{i}}=%s\\%%$\"%(lables[8],))\n",
        "plt.plot(np.arange(0,4,step=1),mean[6][start[index]+36:start[index]+40]/factor,'s-',linewidth=3,linestyle='-',label=\"$\\\\theta_{T_{i}}=%s\\%%$\"%(lables[9],))\n",
        "plt.plot(np.arange(0,4,step=1),mean[6][start[index]+40:start[index]+44]/factor,'s-',linewidth=3,linestyle='-',label=\"$\\\\theta_{T_{i}}=%s\\%%$\"%(lables[10],))\n",
        "\n",
        "plt.rcParams['figure.facecolor'] = 'ivory'\n",
        "plt.rcParams[\"font.weight\"] = \"bold\"\n",
        "plt.rcParams[\"axes.labelweight\"] = \"bold\"\n",
        "ax.set_xticks(np.arange(0,4,step=1))\n",
        "ax.set_xticklabels([\"$0.25N$\",\"$0.5N$\",\"$0.75N$\",\"$1.0N$\"])\n",
        "plt.xticks(fontsize=18,fontweight='bold')\n",
        "plt.yticks(np.arange(0,22,step=2),fontsize=18,fontweight='bold')\n",
        "plt.xlabel('Maximum Out-degree ($D_{out_{max}}$)',fontsize=18,fontweight='bold')\n",
        "plt.ylabel('Final out-degree (mean %)',fontsize=18,fontweight='bold')\n",
        "plt.title(\"{0} group of size, $N=%d$\".format(groups[group])%(N[index],),fontsize=18,fontweight='bold')\n",
        "leg = plt.legend(fontsize=18,loc=\"upper center\",fancybox=True,  bbox_to_anchor=(0.5, 1.5), ncol=3,\n",
        "           framealpha=1.0, shadow=False, borderpad=1)\n",
        "ax.grid(b=True, which='major', color='silver', linestyle='-')\n",
        "\n",
        "plt.savefig('DNDH{0}_FOD_{1}.pdf'.format(groups[group],N[index]),format='pdf', bbox_inches='tight',Transparent=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wZgBAXU1rpUm"
      },
      "source": [
        "## Groups"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "weMVYGVXensX"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "index = 0 # vary from 0 to 4\n",
        "group = 1 # vary from 0 to 1\n",
        "start_c = np.array([0,44,88,132,176])\n",
        "start_l = np.array([220,264,308,352,396])\n",
        "lables = np.array([\"0\",\"10\",\"20\",\"30\",\"40\",\"50\",\"60\",\"70\",\"80\",\"90\",\"100\"])\n",
        "groups = np.array([\"Conservative\",\"Liberal\"])\n",
        "clrs = ['b','g','r','c','m','y','k','lawngreen','darkorange','dodgerblue','lightsteelblue']\n",
        "\n",
        "start=start_l\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(8, 8))\n",
        "plt.plot(np.arange(0,4,step=1),mean[0][start[index]:start[index]+4],'s-',linewidth=3,linestyle='-',color=clrs[0],label=\"$N_{R}=%s\\%%$\"%(lables[0],))\n",
        "plt.plot(np.arange(0,4,step=1),mean[0][start[index]+4:start[index]+8],'s-',linewidth=3,linestyle='-',color=clrs[1],label=\"$N_{R}=%s\\%%$\"%(lables[1],))\n",
        "plt.plot(np.arange(0,4,step=1),mean[0][start[index]+8:start[index]+12],'s-',linewidth=3,linestyle='-',color=clrs[2],label=\"$N_{R}=%s\\%%$\"%(lables[2],))\n",
        "plt.plot(np.arange(0,4,step=1),mean[0][start[index]+12:start[index]+16],'s-',linewidth=3,linestyle='-',color=clrs[3],label=\"$N_{R}=%s\\%%$\"%(lables[3],))\n",
        "plt.plot(np.arange(0,4,step=1),mean[0][start[index]+16:start[index]+20],'s-',linewidth=3,linestyle='-',color=clrs[4],label=\"$N_{R}=%s\\%%$\"%(lables[4],))\n",
        "plt.plot(np.arange(0,4,step=1),mean[0][start[index]+20:start[index]+24],'s-',linewidth=3,linestyle='-',color=clrs[5],label=\"$N_{R}=%s\\%%$\"%(lables[5],))\n",
        "plt.plot(np.arange(0,4,step=1),mean[0][start[index]+24:start[index]+28],'s-',linewidth=3,linestyle='-',color=clrs[6],label=\"$N_{R}=%s\\%%$\"%(lables[6],))\n",
        "plt.plot(np.arange(0,4,step=1),mean[0][start[index]+28:start[index]+32],'s-',linewidth=3,linestyle='-',color=clrs[7],label=\"$N_{R}=%s\\%%$\"%(lables[7],))\n",
        "plt.plot(np.arange(0,4,step=1),mean[0][start[index]+32:start[index]+36],'s-',linewidth=3,linestyle='-',color=clrs[8],label=\"$N_{R}=%s\\%%$\"%(lables[8],))\n",
        "plt.plot(np.arange(0,4,step=1),mean[0][start[index]+36:start[index]+40],'s-',linewidth=3,linestyle='-',color=clrs[9],label=\"$N_{R}=%s\\%%$\"%(lables[9],))\n",
        "plt.plot(np.arange(0,4,step=1),mean[0][start[index]+40:start[index]+44],'s-',linewidth=3,linestyle='-',color=clrs[10],label=\"$N_{R}=%s\\%%$\"%(lables[10],))\n",
        "\n",
        "plt.rcParams['figure.facecolor'] = 'ivory'\n",
        "plt.rcParams[\"font.weight\"] = \"bold\"\n",
        "plt.rcParams[\"axes.labelweight\"] = \"bold\"\n",
        "ax.set_xticks(np.arange(0,4,step=1))\n",
        "ax.set_xticklabels([\"$0.25N$\",\"$0.5N$\",\"$0.75N$\",\"$1.0N$\"])\n",
        "plt.xticks(fontsize=18,fontweight='bold')\n",
        "plt.yticks(np.arange(0,4.5,step=0.5),fontsize=18,fontweight='bold')\n",
        "plt.xlabel('Maximum Out-degree ($D_{out_{max}}$)',fontsize=18,fontweight='bold')\n",
        "plt.ylabel('Number of factions',fontsize=18,fontweight='bold')\n",
        "plt.title(\"{0} group of size, $N=%d$\".format(groups[group])%(N[index],),fontsize=18,fontweight='bold')\n",
        "leg = plt.legend(fontsize=18,loc=\"upper center\",fancybox=True,  bbox_to_anchor=(0.5, 1.5), ncol=3,\n",
        "           framealpha=1.0, shadow=False, borderpad=1)\n",
        "ax.grid(b=True, which='major', color='silver', linestyle='-')\n",
        "\n",
        "plt.savefig('DNDH{0}_Groups_{1}.pdf'.format(groups[group],N[index]),format='pdf', bbox_inches='tight',Transparent=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XC_DEQv7tRps"
      },
      "source": [
        "## Group Size"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qty5zlYYeoeL"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "index = 0 # vary from 0 to 4\n",
        "group = 1 # vary from 0 to 1\n",
        "start_c = np.array([0,44,88,132,176])\n",
        "start_l = np.array([220,264,308,352,396])\n",
        "lables = np.array([\"0\",\"10\",\"20\",\"30\",\"40\",\"50\",\"60\",\"70\",\"80\",\"90\",\"100\"])\n",
        "groups = np.array([\"Conservative\",\"Liberal\"])\n",
        "\n",
        "start=start_l\n",
        "\n",
        "factor = 1#N[index]/100\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(8, 8))\n",
        "plt.plot(np.arange(0,4,step=1),mean[2][start[index]:start[index]+4]/factor,'s-',linewidth=3,linestyle='-',label=\"$\\\\theta_{T_{i}}=%s\\%%$\"%(lables[0],))\n",
        "plt.plot(np.arange(0,4,step=1),mean[2][start[index]+4:start[index]+8]/factor,'s-',linewidth=3,linestyle='-',label=\"$\\\\theta_{T_{i}}=%s\\%%$\"%(lables[1],))\n",
        "plt.plot(np.arange(0,4,step=1),mean[2][start[index]+8:start[index]+12]/factor,'s-',linewidth=3,linestyle='-',label=\"$\\\\theta_{T_{i}}=%s\\%%$\"%(lables[2],))\n",
        "plt.plot(np.arange(0,4,step=1),mean[2][start[index]+12:start[index]+16]/factor,'s-',linewidth=3,linestyle='-',label=\"$\\\\theta_{T_{i}}=%s\\%%$\"%(lables[3],))\n",
        "plt.plot(np.arange(0,4,step=1),mean[2][start[index]+16:start[index]+20]/factor,'s-',linewidth=3,linestyle='-',label=\"$\\\\theta_{T_{i}}=%s\\%%$\"%(lables[4],))\n",
        "plt.plot(np.arange(0,4,step=1),mean[2][start[index]+20:start[index]+24]/factor,'s-',linewidth=3,linestyle='-',label=\"$\\\\theta_{T_{i}}=%s\\%%$\"%(lables[5],))\n",
        "plt.plot(np.arange(0,4,step=1),mean[2][start[index]+24:start[index]+28]/factor,'s-',linewidth=3,linestyle='-',label=\"$\\\\theta_{T_{i}}=%s\\%%$\"%(lables[6],))\n",
        "plt.plot(np.arange(0,4,step=1),mean[2][start[index]+28:start[index]+32]/factor,'s-',linewidth=3,linestyle='-',label=\"$\\\\theta_{T_{i}}=%s\\%%$\"%(lables[7],))\n",
        "plt.plot(np.arange(0,4,step=1),mean[2][start[index]+32:start[index]+36]/factor,'s-',linewidth=3,linestyle='-',label=\"$\\\\theta_{T_{i}}=%s\\%%$\"%(lables[8],))\n",
        "plt.plot(np.arange(0,4,step=1),mean[2][start[index]+36:start[index]+40]/factor,'s-',linewidth=3,linestyle='-',label=\"$\\\\theta_{T_{i}}=%s\\%%$\"%(lables[9],))\n",
        "plt.plot(np.arange(0,4,step=1),mean[2][start[index]+40:start[index]+44]/factor,'s-',linewidth=3,linestyle='-',label=\"$\\\\theta_{T_{i}}=%s\\%%$\"%(lables[10],))\n",
        "\n",
        "plt.rcParams['figure.facecolor'] = 'ivory'\n",
        "plt.rcParams[\"font.weight\"] = \"bold\"\n",
        "plt.rcParams[\"axes.labelweight\"] = \"bold\"\n",
        "ax.set_xticks(np.arange(0,4,step=1))\n",
        "ax.set_xticklabels([\"$0.25N$\",\"$0.5N$\",\"$0.75N$\",\"$1.0N$\"])\n",
        "plt.xticks(fontsize=18,fontweight='bold')\n",
        "plt.yticks(np.arange(188,204,step=2),fontsize=18,fontweight='bold')\n",
        "plt.xlabel('Maximum Out-degree ($D_{out_{max}}$)',fontsize=18,fontweight='bold')\n",
        "plt.ylabel('Population of the largest opinion faction',fontsize=18,fontweight='bold')\n",
        "plt.title(\"{0} group of size, $N=%d$\".format(groups[group])%(N[index],),fontsize=18,fontweight='bold')\n",
        "leg = plt.legend(fontsize=18,loc=\"upper center\",fancybox=True,  bbox_to_anchor=(0.5, 1.5), ncol=3,\n",
        "           framealpha=1.0, shadow=False, borderpad=1)\n",
        "ax.grid(b=True, which='major', color='silver', linestyle='-')\n",
        "\n",
        "plt.savefig('DNDH{0}_GSize_{1}.pdf'.format(groups[group],N[index]),format='pdf', bbox_inches='tight',Transparent=True)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "MC_D/ND/Homo.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}